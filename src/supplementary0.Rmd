---
title: "Supplementary material: The increasing cost of happiness"
author: "R.W. Morris^1,2^, N. Kettlewell^2,3,4^  & N.Glozier^1,5^"
bibliography: ../src/references.bib
csl: ../src/elsevier-harvard.csl
output:  
  html_document:
    reference_docx: ../src/academic_style.docx
always_allow_html: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(brms)
library(flextable)
library(gtsummary)
library(patchwork)

library(bayesplot)

knitr::opts_chunk$set(eval = TRUE,
                      echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      fig.path = "../figures/",
                      ft.align="left")

source("ft_themes.r")
```
\  
\  

1. Central Clinical School, Faculty of Medicine and Health, University of Sydney, NSW, Australia
2. ARC Centre of Excellence for Children and Families over the Life Course, University of Queensland, QLD, Australia
3. School of Economics, University of Technology, NSW, Australia
4. Institute of Labor Economics (IZA), Bonn, Germany
5. Brain and Mind Centre, University of Sydney, NSW, Australia 

\  

**Corresponding author:**  
Professor Nick Glozier  
Faculty of Medicine and Health,   
University of Sydney,  
NSW 2050,  
Australia  
email: nick.glozier@sydney.edu.au  

\  

Draft: `r format(Sys.time(), '%d %B, %Y')`  
Supplementary tables:      4  
Supplementary figures:     6  
  
**keywords:** Subjective wellbeing, household income, HILDA  

\  

***


## Supplementary Material

<br>


#### Sample characteristics  

The broad demographic characteristics of the sample at each sixth year wave are presented below in Table S1. The linear trend as a function of time was estimated for each variable (linear regression of time for continuous variables and Cochrane-Armitage test in the case of binary variables), and Bon-Ferroni adjusted p-values for multiple comparisons are presented (k = 11).    


```{r table_s1}
prop_trend_test <- function(data, variable, by, ...) {
  
  data %>%
    select(x = {{variable}}, y = {{by}}) %>%
    dplyr::filter(complete.cases(.)) %>%
    dplyr::group_by(y) %>%
    dplyr::summarise(
      xsum = sum(x, na.rm = T),
      n = n()
    ) %>%
    {prop.trend.test(x = .$xsum, n = .$n)} %>%
    broom::tidy() %>%
    mutate(method = "Cochrane-Armitage test",
           p.value = p.value * 11,
           p.value = if_else(p.value > 1, 1, p.value))
}

linear_trend_test <- function(data, variable, by, ...) {
  
  data %>%
    select(y = {{variable}}, x = {{by}}) %>%
    dplyr::filter(complete.cases(.)) %>%
    {lm(formula = y ~ ordered(x), data = .)} %>%
    broom::tidy() %>%
    filter(str_detect(term, ".L")) %>%
    mutate(method = "linear trend analysis (parametric)",
           p.value = p.value * 11,
           p.value = if_else(p.value > 1, 1, p.value))
  
}

hilda_data <- read_rds("../data/hilda_data.rds")

hilda_data %>%
  filter(year %in% c(2001, 2007, 2013, 2019)) %>%
  filter(!student, !top_hifdip, (!is.na(losat)|!is.na(gh9))) %>%
  mutate(
    `University Graduates` = edu == "Grad",
    ) %>%
  select(
    year, `Household income ($)` = hh_disp_inc_eq,
    `Life satisfaction` = losat, `Happiness` = gh9, 
    Males = male, `Age (years)` = age, `University Graduates`, #Workforce,
    Unemployed = unemployed, Couples = coupled, #`Relationship status`, 
    `Chronic illness` = chronic, SEIFA, 
    `Household size` = hhsize,
  ) %>% 
  tbl_summary(
    by = year,
    missing = "no",
    statistic = 
      list(all_continuous() ~ "{mean} (±{sd})",
           all_categorical() ~ "{n} ({p}%)"),
    digits = 
      list(all_continuous() ~ 1,
           `Household income ($)` ~ 0),
    missing_text = "(Missing)" 
    ) %>%
  add_p(
    test = list(
      all_continuous() ~ "linear_trend_test",
      all_dichotomous() ~ "prop_trend_test"
    )
  ) %>%
  modify_header(stat_by = "{level}\nN = {style_number(n)}") %>%
  as_flex_table() %>%
  set_caption(caption = "Table S1. Demographic characteristics of the sample") %>%
  align(part = "body") %>%
  valign(valign = "top", part = "header") %>%
  fontsize(size = 9.5, part = "all") %>%
  width(j = 1, width = 1.5) %>%
  width(j = 2:6, width = 1)
```

<br>

Household income and average life satisfaction increased between 2001-2019, while average happiness score decreased slightly over the 19 years. The proportions of each sex were stable over time, as was the proportion of people living as a couple (Couples), average household size and SEIFA index. The percentage unemployed varied with economic conditions however there was no significant positive or negative linear trend. Age and chronic health conditions tended to increase over time. The slight increase in the age of the panel over time (2.3 years) was substantially less than that of a cohort study which would be 18 years. Education levels (i.e., percentage of university graduates) also tended to increase over time.   

Generally, Table S1 supports the view that the HILDA sample was a relatively stable representation of Australian socioeconomic conditions between 2001 and 2019. The importance of the specific demographic variables with a significant linear trend (age, age^2^, education, illness) were tested in regression models of happiness as covariates (see below Figure S3).   

<br><br>

#### Model Comparisons  

**Linear vs non-linear models.** We compared the out-of-sample evidence for the non-linear (piecewise) models with the linear models of income on wellbeing in each year, using the difference in WAIC deviance scores (i.e., WAIC~linear~ — WAIC~piecewise~). Thus a WAIC difference greater than zero indicated evidence for a linear relationship; a WAIC difference less than zero indicated evidence for a nonlinear (piecewise) relationship.   

<br>

##### Figure S1. Linear model evidence (WAIC~linear~ — WAIC~piecewise~)
```{r figure_s1, dpi=300}
here <- "~/Dropbox/HILDA/The-increasing-cost-of-happiness/"

lm_fits = read_rds(paste0(here, "results/lm_gh9_hhoecd_0cov.RDS"))

nl_fits = read_rds(paste0(here, "results/gh9_hhoecd_0cov_tight.RDS"))

# get waic results
map2_dfr(.x = nl_fits, 
         .y = lm_fits, 
         .f = ~{
           loo_compare(.x, .y, criterion = "waic") %>%
             as.data.frame() %>%
             rownames_to_column("model") %>%
             as_tibble()
         },
         .id = "year") %>%
  filter(elpd_diff != 0) %>%
  mutate(
    year = extract_numeric(year),
    model = if_else(model == ".x", "nl", "lm"),
    waic_diff = 2 * elpd_diff, # lm disadvantage
    se = 2 * se_diff,
    wellbeing = "Happiness"
  ) -> waic_happiness

nl_fits_losat = read_rds(paste0(here, "results/losat_hhoecd_0cov.RDS"))

lm_fits_losat = read_rds(paste0(here, "results/lm_losat_hhoecd_0cov.RDS"))

# plot waic results
map2_dfr(.x = nl_fits_losat, 
         .y = lm_fits_losat, 
         .f = ~{
           loo_compare(.x, .y, criterion = "waic") %>%
             as.data.frame() %>%
             rownames_to_column("model") %>%
             as_tibble()
         },
         .id = "year") %>%
  filter(elpd_diff != 0) %>%
  mutate(
    year = extract_numeric(year),
    model = if_else(model == ".x", "nl", "lm"),
    waic_diff = if_else(model == "lm", 
                        2 * elpd_diff,   # nl advantage
                        -2 * elpd_diff), # nl advantage
    se = 2 * se_diff,
    wellbeing = "Satisfaction"
  ) -> waic_satisfaction

bind_rows(waic_happiness, waic_satisfaction) %>% 
  ggplot(aes(x = waic_diff, y = year, color = wellbeing)) +
    geom_vline(aes(xintercept = 0), color = "grey90") +
    geom_pointrange(aes(xmin = waic_diff - se*1.96, xmax = waic_diff + se*1.96)) +
    scale_y_continuous(breaks = c(2001, 2007, 2013, 2019)) +
    ft_theme() +
    labs(x = "deviance", y = "") +
    facet_wrap(~wellbeing, ncol = 1) +
    scale_color_manual(values  = c("#8F2727", "#005b96")) +
    theme(legend.position = "none")
```

```
Figure S1 legend: Differences in WAIC scores (deviance units) for a linear fit over a piecewise fit for happiness (red) and satisfaction (blue). The filled circle indicates the mean of the difference and the horizontal bars represents the 95% interval. A difference below zero (grey vertical line) is support for the piecewise model (a difference above zero is support for the linear model).
```  


<br>

The difference in WAIC scores for each model revealed the nonlinear (piecewise) fits of _happiness_, but not _satisfaction_, provided superior out-of-sample accuracy over a linear fit in each year. Figure S1 shows the 95% interval of the differences in WAIC scores clearly distinguished the advantage of the nonlinear fits for happiness with no overlap with zero in any year. By contrast, the difference in WAIC between the linear and nonlinear models of life satisfaction was not distinguished from zero for most years (with the exception of 2017 and 2008), indicating the (out-of-sample) accuracy of the two models was largely indistinguishable over the 19 years. Overall the evidence suggested that household income has a distinct nonlinear relationship with happiness; implying the existence of a change point or difference in slopes at different levels of household income. This is consistent with the only meta-analysis conducted in this area, over ten years ago, which concluded the linear relationship between income and life satisfaction is stronger than that with happiness [@howell2008relation]. It is also worth noting that a linear function between income and life satisfaction is consistent with the majority of  research since then [@stevenson2013subjective]. 

**Conditional vs unconditional models of happiness.** Table S1 (above) showed the specific variables that changed over the 19 years between 2001-2019. In particular, the number of university graduates, average age and the incidence of chronic illness increased slighty over the period. Including these variables as covariates in any model (i.e,. a conditional model such that *P*( $y$ | income, age, education illness)) will improve the in-sample fit (e.g., R^2^), and also adjust the parameter estimates of interest (e.g., change point) conditional upon their common association with happiness. Given the general aim of the main paper was to describe the temporal change in functional form between happiness and income in Australia, regardless of any other variable (i.e., an unconditional model of *P*($y$| income)) or sampling differences, neither the in-sample fit nor the conditional model estimates are directly relevant. Nevertheless, the importance of these variables in mediating the changes we observed in the unconditional model are relevant, and so we calculated the estimates from conditional piecewise models including age, age^2^, sex, education  (university degree), chronic illness for each year below to confirm the pattern of temporal change was similar. Figure S2 shows the addition of these covariates did not change the trend in change point parameter estimates (red) relative to the unconditional parameter estimates (grey) over the 19 years.  

<br>

##### Figure S2. Conditional model parameters  
```{r figure_s2, fig.height=8, dpi=300}
here <- "~/Dropbox/HILDA/The-increasing-cost-of-happiness/"

nl_fits = read_rds(paste0(here, "results/gh9_hhoecd_0cov_tight.RDS"))

nl_fits_5cov = read_rds(paste0(here, "results/gh9_hhoecd_5cov_tight.RDS"))

income_params <- read_rds("../results/gh9_hhoecd_summary.RDS")

posteriors_5c <- map_dfr(nl_fits_5cov, as.data.frame, .id = "fit") %>%
  left_join(bind_rows(income_params, .id = "fit")) %>%
  mutate(omega_dollars = (b_omega_Intercept * sd + mean)/1000) %>%
  as_tibble()

param_key = c(
  omega_dollars = "Change point ($000s)",
  b_b0_Intercept = paste0("Intercept (\u03b2", "0)"),
  b_b1_Intercept = paste0("Pre-slope (\u03b2", "1)"),
  b_b2_Intercept = paste0("Post-slope (\u03b2", "2)")
)

posteriors_5c %>%
  select(fit, contains("b0"), contains("b1"), contains("b2"), omega_dollars) %>%
  gather(key = "param", val = "sample", -fit) %>%
  mutate(
    year = extract_numeric(fit),
    param = recode_factor(param, !!!param_key)
  ) %>% 
  group_by(param, year) %>%
  summarise(
    low = quantile(sample, probs = 0.05, na.rm=T),
    expected = quantile(sample, probs = 0.5, na.rm=T),
    upp = quantile(sample, probs = 0.95, na.rm=T)
  ) %>%
  mutate(model = "conditional") -> parameter_summary_5c

posteriors_0c <- map_dfr(nl_fits, as.data.frame, .id = "fit") %>%
  left_join(bind_rows(income_params, .id = "fit")) %>%
  mutate(omega_dollars = (b_omega_Intercept * sd + mean)/1000) %>%
  as_tibble()

posteriors_0c %>%
  select(fit, contains("b0"), contains("b1"), contains("b2"), omega_dollars) %>%
  gather(key = "param", val = "sample", -fit) %>%
  mutate(
    year = extract_numeric(fit),
    param = recode_factor(param, !!!param_key)
  ) %>% 
  group_by(param, year) %>%
  summarise(
    low = quantile(sample, probs = 0.05, na.rm=T),
    expected = quantile(sample, probs = 0.5, na.rm=T),
    upp = quantile(sample, probs = 0.95, na.rm=T)
  ) %>%
  mutate(model = "unconditional") -> parameter_summary_0c

bind_rows(parameter_summary_0c, parameter_summary_5c) %>%
  ggplot(aes(y = year, x = expected, color = model)) +
  geom_pointrange(aes(xmin = low, xmax = upp), position = position_dodge(width = 0.75)) +
  scale_y_continuous(breaks = c(2001, 2007, 2013, 2019)) +
  facet_wrap(~param, scales = "free_x") +
  ft_theme(base_size = 12) +
  scale_color_manual(values = c("#C79999", "grey65")) +
  theme(legend.position = "none",
        axis.title = element_blank())
```
```
Figure S2 legend: Comparison of the conditional parameter estimates (red) and unconditional parameter estimates (grey) in the change point model of income on happiness. The conditional models included covariates for age, age squared, sex, education, and illness. Horizontal bar represents the 95% credible region and the solid point indicates the expected value (median) of each distribution.
```  

<br>

The parameter estimates of the conditional model (red) were adjusted for the broad demographic variables which tended to increase over the 19 years in our sample (age, education, illness); however the pattern of changes over time was comparable to the unconditional model (grey), indicating these temporal trends were not responsible for the evolution in the change point between income and happiness.  

<br><br>

#### Additional non-linear fits

**Log-linear models.** The relationship between happiness and income is often described as log-linear [e.g., @kahneman2010high]. Under this view, similar proportional changes in income or wealth produce similar evaluations of satisfaction or happiness, rather than the absolute change. That is, a \$100 increase in wealth will produce a greater impact on someone earning a minimum wage than someone earning many orders of magnitude of that amount. Likewise, the piecewise model that we employed can also adopt an increasing monotonic function whose slope reduces with wealth, albeit with a single identifiable change-point rather than a smooth curve. However our main thesis is not committed to a function with a single discrete changepoint; only that the slope between income and happiness is unequal at different levels of income, and the function is shifting to the right over time. The choice between functions is somewhat arbitrary, since a log-linear function is as easily consistent with our thesis as the piecewise function we described in the main paper. To resolve this, we compared the evidence for a log-linear fit against the piecewise fits according to their WAIC scores. Thus a WAIC difference less than zero indicated evidence for the piecewise fit over the log-linear fit (i.e., greater out-of-sample accuracy).   

<br>

##### Figure S3. Log-linear model evidence (WAIC~log-linear~ — WAIC~piecewise~)
```{r, figure_s3, fig.height=3.5, dpi=300}
here <- "~/Dropbox/HILDA/The-increasing-cost-of-happiness/"

nl_fits = read_rds(paste0(here, "results/gh9_hhoecd_0cov_tight_x0.RDS"))

log_fits = read_rds(paste0(here, "results/log_gh9_hhoecd_0cov.RDS"))

# get waic results
map2_dfr(.x = nl_fits, 
         .y = log_fits, 
         .f = ~{
           loo_compare(.x, .y, criterion = "waic") %>%
             as.data.frame() %>%
             rownames_to_column("model") %>%
             as_tibble()
         },
         .id = "year") %>%
  filter(elpd_diff != 0) %>%
  mutate(
    year = extract_numeric(year),
    model = if_else(model == ".x", "nl", "log-linear"),
    waic_diff = 2 * elpd_diff, # lm disadvantage
    se = 2 * se_diff
  ) %>%
  ggplot(aes(x = waic_diff, y = year)) +
  geom_vline(aes(xintercept = 0), color = "grey90") +
  geom_pointrange(aes(xmin = waic_diff - se*1.96, xmax = waic_diff + se*1.96),
                 color = "#ffcc80") +
  scale_y_continuous(breaks = c(2001, 2007, 2013, 2019)) +
  ft_theme() +
  labs(x = "deviance", y = "")
```
```
Figure S3 legend: The joint distribution between wellbeing and income for a single year, imposed by the priors.
```  

<br>

The piecewise fit was superior to a log-linear fit of income on happiness in each year, although the difference was less distinguishable in 2003, 2006, and 2008 where the 95% interval overlapped zero. This indicates the evidence for a piecewise model was generally greater than for a log-linear model, however it does not necessarily imply the presence of a discrete change point exists. In a Bayesian change point model, the estimated location of the change point in each year is not a single point but is rather a probability distribution of income values that extends over the entire range of household income. Importantly the width of the 95% posterior probability distribution in Figure 2 indicates the change point location is likely over a range of values, on average ±$9.15K, which implies a more or less smooth function over that range.   


<br><br>

#### Prior and residual checks   

We used regularizing Guassian priors centred on zero, with Normal(0, 0.1) for each *&beta;*, and a Normal(0, 0.5) for *&omega;*. A plot of the joint distribution between income and wellbeing imposed by the priors alone confirmed there was no apparent slope or change point implied by their regularizing effect.  

##### Figure S4. Prior predictive check  
```{r figure_s4, dpi=300}
load(paste0(here, "results/prior_predictions.Rdata"))

prior_predictions %>%
  ggplot(aes(x = hh_disp_inc_eq/1000, y = Estimate, group = 1)) +
  geom_point(size = 0.1, alpha = 0.1) +
  stat_smooth(color = "#8F2727", size = 0.5, se = F) +
  xlim(c(0, 300)) +
  labs(y = "Wellbeing estimate (SD units)", x = "Household income ($000s)") +
  theme_test()
```
```
Figure S4 legend: The joint distribution between wellbeing and income for a single year, imposed by the priors. The solid blue line indicates a smoothed average (loess).
```  
<br><br>

Examination of the residual plots from the piecewise models of happiness confirms the residuals were evenly distributed around zero and there was little indication of heteroscedascity. Overall, there was little evidence that the piecewise models of happiness were not appropriate for the data.  

<br>

##### Figure S5. Residual plots for piecewise happiness models
```{r figure_s5, fig.height=9, fig.width=9}
# https://www.flutterbys.com.au/stats/tut/tut7.2b.html
# 
# 
# residual_fits <- map_dfr(nl_fits, ~{
#   
#   d0 <- resid(.x) %>%
#     as_tibble() %>%
#     select(resids = Estimate)
#   
#   d1 <- fitted(.x) %>%
#     as_tibble() %>%
#     select(fitteds = Estimate)
#   
#   bind_cols(d0, d1)
#   
#   }, .id = "fit") %>%
#   mutate(year = extract_numeric(fit))
# 
# save(residual_fits, file = paste0(here, "results/residual_fits.Rdata"))

load(paste0(here, "results/residual_fits.Rdata"))

residual_fits %>%
  group_by(year) %>%
  slice_sample(n = 1000) %>% # to reduce overplotting
  ggplot(aes(x = fitteds, y = resids)) +
    geom_point(alpha = 0.1, size = 0.1) +
    facet_wrap(~year, scales = "free") +
    theme_test()
```


```
Figure S5 legend: The joint distribution between residual and fitted values for each year.
``` 

<br><br>

#### Parameter and fit summary statistics 

There were _N_ = 59,876 total observations. 4000 samples (post-warmup) were drawn using sampling(NUTS). For each parameter, Bulk_ESS and Tail_ESS are effective sample size (ESS) measures, and Rhat is the potential scale reduction factor on split chains. In each case the Rhat approached 1, indicating convergance. Each ESS _n_ > 300, which is a conservative threshold for estimation.  

<br>

```{r table_s2, ft.align="left"}
param_key = c(
  b0_Intercept = "Intercept",
  b1_Intercept = "Pre-slope",
  b2_Intercept = "Post-slope",
  omega_Intercept = "Change-point"
)

map_dfr(nl_fits, 
        .f = ~{
          fit_summary <- summary(.x) 
          
          sigma_summary <- fit_summary$spec_pars %>%
            as_tibble(rownames = "Parameter")
          
          fit_summary$fixed %>%
            as_tibble(rownames = "Parameter") %>%
            bind_rows(sigma_summary) %>%
            select(Parameter, everything())
          
          },
        .id = "Year") %>%
  mutate(
    Year = str_remove(Year, "fit"),
    Parameter = recode_factor(Parameter, !!!param_key)
    ) %>%
  flextable() %>%
  merge_v(j = 1) %>%
  valign(j = 1, valign = "top") %>%
  bg(i = ~Year %in% seq(2001, 2019, 2), 
     bg = "grey90", 
     part = "body") %>%
  colformat_num(j = 3:6, digits= 3) %>%
  colformat_num(j = 7, digits= 1) %>%
  set_caption("Table S2. Piecewise parameter estimates and fit statistics for happiness") %>%
  autofit()
```

<br>

```{r table_s3, ft.align="left"}
param_key = c(
  b0_Intercept = "Intercept",
  b1_Intercept = "Pre-slope",
  b2_Intercept = "Post-slope",
  omega_Intercept = "Change-point"
)

map_dfr(lm_fits_losat, 
        .f = ~{
          fit_summary <- summary(.x) 
          
          sigma_summary <- fit_summary$spec_pars %>%
            as_tibble(rownames = "Parameter")
          
          fit_summary$fixed %>%
            as_tibble(rownames = "Parameter") %>%
            bind_rows(sigma_summary) %>%
            select(Parameter, everything())
          
          },
        .id = "Year") %>%
  mutate(
    Year = str_remove(Year, "fit"),
    Parameter = recode_factor(Parameter, !!!param_key)
    ) %>%
  flextable() %>%
  merge_v(j = 1) %>%
  valign(j = 1, valign = "top") %>%
  bg(i = ~Year %in% seq(2001, 2019, 2), 
     bg = "grey90", 
     part = "body") %>%
  colformat_num(j = 3:6, digits= 3) %>%
  colformat_num(j = 7, digits= 1) %>%
  set_caption("Table S3. Linear parameter estimates and fit statistics for life satisfaction") %>%
  autofit()
```


<br><br>

#### Model predictions (2001-2019)

The posterior estimates of the piecewise model indicated that the relationship between happiness and income changed over time between 2001 and 2019. One implication of such a change is the disparity in happiness between income groups has increased. This will occur as more people fall below the change point over time and so are subject to the steep region of the function where income and happiness are strongly related. To directly examine the implications of our model for such inequities in happiness, we used the model to estimate or _predict_ the happiness of two different income levels: one income level which was above the change point in 2001 but fell below it by 2019 (\$50K/yr); and another level which always remained above the change points over the same period (\$75K/yr). Figure S8 below presents the happiness levels (in SD units/year) for each income level as well as the difference in happiness between them (∆).  

<br>

##### Figure S6. Happiness (SD units) at $50K/yr and $75K/yr from 2001-2019  
```{r figure_s6, fig.width=7, fig.height=5, dpi=300}
here <- "~/Dropbox/HILDA/The-increasing-cost-of-happiness/"

nl_fits = read_rds(paste0(here, "results/gh9_hhoecd_0cov_tight.RDS"))

# Optional
# nl_fits_5cov = read_rds(
#   paste0(here, "results/fits/excl_topcodes/sd/gh9_hhoecd_5cov_tight.RDS")
# )

income_params <- read_rds("../results/gh9_hhoecd_summary.RDS")

bind_rows(income_params, .id = "fit") %>%
  mutate(low = (40000 - mean)/sd,
         high = (75000 - mean)/sd) %>%
  column_to_rownames(var = "fit") %>%
  as.matrix() -> fixed_income_hash

colnames(fixed_income_hash) <- NULL

fixed_income_fit <- tibble()

for (name in names(nl_fits)) {
  
  newdat = data.frame(
    dollars = fixed_income_hash[name, 3:4]
  )
  
  df <- fitted(nl_fits[[name]], newdata = newdat) %>% 
    as_tibble() %>%
    mutate(Dollars = c("$50K", "$75K"),
           
           fit = name)
  
  fixed_income_fit <- bind_rows(fixed_income_fit, df)
  
}

fixed_income_fit %>%
  mutate(year = extract_numeric(fit)) %>%
  select(Estimate, Dollars, year) %>%
  filter(Dollars %in% c("$75K", "$50K")) %>%
  spread(Dollars, Estimate) %>%
  mutate(`$75K - $50K (∆)` = `$75K` - `$50K`) %>%
  gather(income, happiness, -year) %>%
  mutate(income = fct_relevel(income, "$50K", "$75K")) %>%
  ggplot(aes(x = year, y = happiness, color = income)) +
  geom_point(size = 4, alpha = 0.25) +
  geom_smooth(method = "loess", se = F, span = 3) +
  facet_wrap(~income) +
  labs(caption = "Source:     HILDA, University of Melbourne
                 Predicted happiness scores (SD unit) from piecewise regression on real household income", 
       x = "", y = "") -> p


p +
  ft_theme() +
  ggthemes::scale_colour_wsj() +
  theme(legend.position = "none",
        plot.title = element_text(size = 19),
        strip.text = element_text(size = 12))
```

```
Figure S6 legend: The difference (∆) in happiness between a household income of $50K per year and a household income of $75K per year has increased between 2001 and 2019.
```  

<br>

Figure S6 shows the disparity in happiness between two fixed income levels, \$50K/year (traversing the change points) and \$75K/year (above the change points). In 2001, a household income of \$50K/year achieved an above average level of happiness relative to everyone else that year, however by 2019 happiness had declined to lower than average levels relative to the population. By contrast, a household income of \$75K/year enjoyed a higher than average level of happiness for the entire period. The difference (∆) in happiness between these two income levels doubled over the period. The increasing disparity in happiness between the rich and the poor implies that happiness has became more inequitable over time.  


<br><br>

#### In-sample fit statistics

Our primary objective was to understand the relationships between the parameters of our model, and so in-sample fit statistics such as R^2^ are irrelevant for this objective. Moreover, our use of regularized priors will bias such in-sample estimates towards zero as regularization deliberately sacrifices in-sample variance for out-of-sample accuracy, which obviously hinders interpretation of the in-sample values. Nevertheless, some readers may find it useful to compare the in-sample fit statistics between the three different model types employed here: piecewise, linear and log-linear, as well as between the conditional and unconditional models. Because the usual fit statistics such as R^2^ present a problem for Bayesian fits, as the variance of the predicted values can be larger than the variance of the data results in R^2^ values greater than 1, we present the in-sample statistics from frequentist OLS model fits (without regularization or penalized likelihoods).   

```{r table_s4}
library(segmented)

hilda_data %>%
  filter(
    !student,
    !top_hifdip
  ) %>%
  filter(hh_disp_inc_eq > 0) %>%
  group_by(year) %>%
  transmute(
    y = as.vector(scale(gh9)),
    dollars = hh_disp_inc_eq,
    male = male,
    age = as.vector(scale(age)),
    age_sq = age^2,
    grad = edu %in% c("Grad", "Postgrad"),
    illness = chronic,
    weights = as.vector(scale(weights))
  ) %>%
  na.omit() %>%
  nest() -> nested_data

nested_data %>%
  mutate(
    pw_fit = map(data, ~segmented(lm(
      formula = y ~ dollars, 
      data = .x),
      seg.Z = ~dollars)),
    pw_fit_c = map(data, ~segmented(lm(
      formula = y ~ dollars + male + age + age_sq + grad + illness + weights, 
      data = .x),
      seg.Z = ~dollars)),
    lin_fit = map(data, ~lm(
      formula = y ~ dollars, 
      data = .x)),
    lin_fit_c = map(data, ~lm(
      formula = y ~ dollars + male + age + age_sq + grad + illness + weights, 
      data = .x)),
    log_fit = map(data, ~lm(
      formula = y ~ log(dollars), 
      data = .x)),
    log_fit_c = map(data, ~lm(
      formula = y ~ log(dollars) + male + age + age_sq + grad + illness + weights, 
      data = .x))
    ) -> nested_models

bind_rows(
  map_dfr(nested_models$log_fit, broom::glance) %>%
    mutate(model = "log", year = 2001:2019),
  map_dfr(nested_models$lin_fit, broom::glance) %>%
    mutate(model = "lin", year = 2001:2019),
  map_dfr(nested_models$pw_fit, broom::glance) %>%
    mutate(model = "pw", year = 2001:2019),
  map_dfr(nested_models$log_fit_c, broom::glance) %>%
    mutate(model = "logc", year = 2001:2019),
  map_dfr(nested_models$lin_fit_c, broom::glance) %>%
    mutate(model = "linc", year = 2001:2019),
  map_dfr(nested_models$pw_fit_c, broom::glance) %>%
    mutate(model = "pwc", year = 2001:2019)
) -> model_summaries

model_summaries %>%
  select(model, year, r.squared) %>%
  spread(model, r.squared) %>%
  flextable() %>%
  colformat_num(j = 2:7, digits = 3) %>%
  set_caption("Table S4. In-sample fit statistics (R-squared)") %>%
  set_header_labels(
    lin = "Linear", 
    linc = "Linear\n(conditional)",
    log = "Log-linear",
    logc = "Log-linear\n(conditional)",
    pw = "Piecewise",
    pwc = "Piecewise\n(conditional)") %>%
  valign(i = 1, valign = "top", part = "header") %>%
  width(j = 2:7, width = 1)
```

<br>

A comparison of the relative differences in R^2^ values between models indicates the piecewise model produced a slightly higher in-sample fit over the other two models, while the linear model tended to have the lowest R^2^. The log-linear fit varied between both over the 19 years. As expected, adding covariates increased the R-squared in each case, but it did not change the relative difference between models.  

Three things need to be observed when interpreting the R^2^ values: 1) While the R^2^ between income and happiness is low (~2% and ~14% in the unconditional and conditional models, respectively), the aggregate effect over the wider population (e.g., 25M in Australia) will be much larger; 2) Happiness (and to a lesser extent, income) is an imperfect and noisy measure so any effect of income on happiness is likely to be larger than that measured here; 3) Finally, happiness is measured on a subjective and arbitrary Likert scale so a small change in happiness at different points in the scale may represent a large change in some other functional/real-world outcome (e.g., risk of suicide). This is all to say that quantifying the real-world impact of small changes in variation reported here is difficult and speculative without further investigation.  

<br><br>

## References

